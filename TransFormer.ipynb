{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer"
      ],
      "metadata": {
        "id": "FrWjJbgSVvV9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcpDUIH_TxNR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input Layer"
      ],
      "metadata": {
        "id": "YOT8YtPLV0fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "seq = 4\n",
        "word_vector = 10"
      ],
      "metadata": {
        "id": "yemU4cuZWe1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.Tensor(batch_size, seq, word_vector) #학습 불가능"
      ],
      "metadata": {
        "id": "oMuailjaVwij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi-CLQgyWScz",
        "outputId": "8325f58e-b2f1-48d2-b155-3cc2457e2263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.6816e-44,  0.0000e+00, -1.0133e+18,  3.2200e-41,  1.5891e-42,\n",
              "           3.2200e-41, -1.0134e+18,  3.2200e-41,  1.6816e-44,  3.2200e-41],\n",
              "         [-1.0133e+18,  3.2200e-41,  1.5905e-42,  3.2200e-41, -1.0134e+18,\n",
              "           3.2200e-41,  1.6816e-44,  3.2200e-41, -1.0134e+18,  3.2200e-41],\n",
              "         [ 1.5961e-42,  3.2200e-41, -1.0134e+18,  3.2200e-41,  1.6816e-44,\n",
              "           3.2200e-41, -1.0134e+18,  3.2200e-41,  3.3631e-44,  3.2200e-41],\n",
              "         [-8.6093e-34,  4.5877e-41,  1.4013e-45,  3.2200e-41,  1.5414e-44,\n",
              "           1.7830e+19,  1.4013e-45,  1.1210e-44,  1.4013e-45,  1.8217e-44]]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = \"i am a dream\"\n",
        "tokenized_input = [\"i\",\"am\",\"a\",\"dream\"]\n",
        "input_idx = [1, 34, 7, 45]"
      ],
      "metadata": {
        "id": "kOY8TGndWi-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.tensor(input_idx)"
      ],
      "metadata": {
        "id": "qGCA32FvXivL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_emb = nn.Embedding(100,10) #학습 가능"
      ],
      "metadata": {
        "id": "qyFqtxixXJcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_emb = word_emb(input_tensor)"
      ],
      "metadata": {
        "id": "a6GQRPkSXVjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##positional encoding"
      ],
      "metadata": {
        "id": "EizizR9AX1GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#position_enc = nn.Embedding(MAX_TOKEN, WORD_DIM)"
      ],
      "metadata": {
        "id": "okb3I9WkXdHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position_idx = [0,1,2,3]\n",
        "position_tensor = torch.tensor(position_idx)"
      ],
      "metadata": {
        "id": "f-PkT5uYZBre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#position_emb = position_enc(position_tensor)"
      ],
      "metadata": {
        "id": "ZNKw2QnvY-bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final_emb = token_emb+position_emb"
      ],
      "metadata": {
        "id": "kLhADMQxYXH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final_emb"
      ],
      "metadata": {
        "id": "G7xeeucLZVG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config():\n",
        "    max_position_embeddings = 20\n",
        "    dim_token_emb = 10\n",
        "    num_dict = 100"
      ],
      "metadata": {
        "id": "ar-Ee3H6ZyuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config()"
      ],
      "metadata": {
        "id": "lW4lihW4aBHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.token_embeddings = nn.Embedding(config.num_dict,config.dim_token_emb)\n",
        "        self.position_embbeddings = nn.Embedding(config.max_position_embeddings, config.dim_token_emb)\n",
        "\n",
        "    def forward(self, input):\n",
        "        word_emb = self.token_embeddings(input)\n",
        "        position_len = input.size()[0]\n",
        "        position_idx = torch.arange(position_len, dtype = torch.long).unsqueeze(0)\n",
        "        position_emb = self.position_embbeddings(position_idx)\n",
        "\n",
        "        embedding = word_emb + position_emb\n",
        "        return embedding"
      ],
      "metadata": {
        "id": "5E3pG9N1ZYou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_layer = Embedding(config)"
      ],
      "metadata": {
        "id": "uNOQ8xzXa5ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = emb_layer(input_tensor)"
      ],
      "metadata": {
        "id": "MZJ3Z5ZocLlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK4vRa2KP5wm",
        "outputId": "11a5bdb4-c2a5-443b-9dfd-51086410cf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multi-Head Attention"
      ],
      "metadata": {
        "id": "z98uQBncjCw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(config.emb_dim, config.out_dim)\n",
        "        self.key = nn.Linear(config.emb_dim, config.out_dim)\n",
        "        self.value = nn.Linear(config.emb_dim, config.out_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        q = self.query(input)\n",
        "        k = self.key(input)\n",
        "        v = self.value(input)\n",
        "\n",
        "        att_score = F.softmax(torch.bmm(q, k.transpose(1,2)) / math.sqrt(q.size(1)), -1)\n",
        "        self_att_rst = torch.bmm(att_score, v)\n",
        "        return self_att_rst"
      ],
      "metadata": {
        "id": "QuPDEuNkvzQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.s_att = SelfAttention(config)\n",
        "\n",
        "    def forward(self, input):\n",
        "        rst_list = []\n",
        "        for _ in range(config.num_head):\n",
        "            rst_list.append(self.s_att(input))\n",
        "        output = torch.concat(rst_list, -1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "1vkHXvYevbA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = emb.size(2)"
      ],
      "metadata": {
        "id": "RX5NmUCNcS3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_head = 2"
      ],
      "metadata": {
        "id": "LtWoDxt7qm_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = nn.Linear(emb_dim, emb_dim//num_head)\n",
        "key1 = nn.Linear(emb_dim, emb_dim//num_head)\n",
        "value1 = nn.Linear(emb_dim, emb_dim//num_head)\n",
        "\n",
        "query2 = nn.Linear(emb_dim, emb_dim//num_head)\n",
        "key2 = nn.Linear(emb_dim, emb_dim//num_head)\n",
        "value2 = nn.Linear(emb_dim, emb_dim//num_head)"
      ],
      "metadata": {
        "id": "pLfryP78jgRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = query1(emb)\n",
        "k1 = key1(emb)\n",
        "v1 = value1(emb)\n",
        "\n",
        "q2 = query2(emb)\n",
        "k2 = key2(emb)\n",
        "v2 = value2(emb)"
      ],
      "metadata": {
        "id": "MMwWzlgHkyg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att_score1 = F.softmax(torch.bmm(q1, k1.transpose(1,2)) / math.sqrt(q1.size(1)), -1)\n",
        "self_att_rst1 = torch.bmm(att_score1, v1)"
      ],
      "metadata": {
        "id": "fXD2GoLqk52E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att_score2 = F.softmax(torch.bmm(q2, k2.transpose(1,2)) / math.sqrt(q2.size(1)), -1)\n",
        "self_att_rst2 = torch.bmm(att_score2, v2)"
      ],
      "metadata": {
        "id": "CIjj6AtwmMga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self_att_rst1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSk-GV7_nnZo",
        "outputId": "5a82d704-49c3-4d6b-abe8-59174de6d884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5290,  0.1782, -0.3014,  0.3114,  0.3776],\n",
              "         [-0.5913,  0.1063, -0.2973,  0.2388,  0.3592],\n",
              "         [-0.6100,  0.2929, -0.3398,  0.4293,  0.5349],\n",
              "         [ 0.0471, -0.1012, -0.0521,  0.0746, -0.2128]]],\n",
              "       grad_fn=<BmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "self_att_rst2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JXfgFISn5El",
        "outputId": "a741bd59-a55f-4055-918c-d08efbfe51b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1992,  0.5415,  0.2673, -0.2996, -0.2124],\n",
              "         [-0.1681,  0.5240,  0.2687, -0.2511, -0.3574],\n",
              "         [-0.4314,  0.7083,  0.2692, -0.3083, -0.5256],\n",
              "         [-0.1382,  0.4809,  0.3331, -0.1889, -0.5401]]],\n",
              "       grad_fn=<BmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concat_rst = torch.cat((self_att_rst1, self_att_rst2), -1)"
      ],
      "metadata": {
        "id": "C0_rpGnwpEDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concat_rst.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYKMWmN6rq-6",
        "outputId": "cdc912df-6d19-42f6-b03a-978f288df30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FF(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(config.emb_dim, config.hid_dim)\n",
        "        self.act =  nn.ELU()\n",
        "        self.lin2 = nn.Linear(config.hid_dim, config.emb_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = self.lin1(input)\n",
        "        input = self.act(input)\n",
        "        input = self.lin2(input)\n",
        "        return input"
      ],
      "metadata": {
        "id": "nzBKnaKq0AqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.norm2 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.attention = MultiHeadAttention(config)\n",
        "        self.ff = FF(config)\n",
        "\n",
        "    def forward(self, input):\n",
        "        concat_rst = self.attention(input)\n",
        "        nor_rst1 = self.norm1(concat_rst + input)\n",
        "        f_rst = self.ff(nor_rst1)\n",
        "        nor_rst2 = self.norm2(f_rst + nor_rst1)\n",
        "        return nor_rst2"
      ],
      "metadata": {
        "id": "JkP50GpvzLxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_rst = concat_rst + emb"
      ],
      "metadata": {
        "id": "BNgKgV6pr49i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal = nn.BatchNorm1d(4)"
      ],
      "metadata": {
        "id": "ONlt-vB3sIqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_nor_rst = normal(add_rst)"
      ],
      "metadata": {
        "id": "lWo4gvB8sPmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fnn_dim = add_nor_rst.size(-1)"
      ],
      "metadata": {
        "id": "nGuAVzHHslTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hid_dim = 50"
      ],
      "metadata": {
        "id": "pCur_cCAs5h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin1 = nn.Linear(fnn_dim, hid_dim)\n",
        "act =  nn.ELU()\n",
        "lin2 = nn.Linear(hid_dim, fnn_dim)"
      ],
      "metadata": {
        "id": "wJaanyMTsTAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fdd_rst = lin2(act(lin1(add_nor_rst)))"
      ],
      "metadata": {
        "id": "dJ3j7kJxtDga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_add_rst = fdd_rst + add_nor_rst"
      ],
      "metadata": {
        "id": "zz9aP-GitJPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_add_nor_rst = normal(f_add_rst)"
      ],
      "metadata": {
        "id": "9SrsC4T-tUjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_add_nor_rst"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp0fUIH9tW6E",
        "outputId": "27b62756-9aa6-4114-c0b5-ae907f2998a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.2386,  0.5033, -1.4657,  0.3807,  0.3138,  0.1966,  2.0507,\n",
              "           0.7117, -0.8151, -0.6374],\n",
              "         [-2.0080,  0.5758, -0.3328, -0.8314, -0.4042,  0.2466,  2.0832,\n",
              "           0.3920, -0.0581,  0.3370],\n",
              "         [-0.9015,  0.5577,  0.2818, -0.0715,  2.5628, -0.4882, -0.2587,\n",
              "          -1.1025,  0.2271, -0.8070],\n",
              "         [ 0.4371,  0.5421,  0.0398, -1.6878, -0.9826, -1.0605,  2.0865,\n",
              "           0.4209, -0.0043,  0.2086]]], grad_fn=<NativeBatchNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y1Y8lyAwtYxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모듈화"
      ],
      "metadata": {
        "id": "tm6vDGaWvI9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config():\n",
        "    max_position_embeddings = 20\n",
        "    dim_token_emb = 10\n",
        "    num_dict = 100\n",
        "    emb_dim = 10\n",
        "    num_head = 2\n",
        "    out_dim = emb_dim//num_head\n",
        "    hidden_size = 4\n",
        "    hid_dim = 50"
      ],
      "metadata": {
        "id": "4sF5ihRdvLOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.token_embeddings = nn.Embedding(config.num_dict,config.dim_token_emb)\n",
        "        self.position_embbeddings = nn.Embedding(config.max_position_embeddings, config.dim_token_emb)\n",
        "\n",
        "    def forward(self, input):\n",
        "        word_emb = self.token_embeddings(input)\n",
        "        position_len = input.size()[0]\n",
        "        position_idx = torch.arange(position_len, dtype = torch.long).unsqueeze(0)\n",
        "        position_emb = self.position_embbeddings(position_idx)\n",
        "\n",
        "        embedding = word_emb + position_emb\n",
        "        return embedding"
      ],
      "metadata": {
        "id": "B7uitLcnvXg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(config.emb_dim, config.out_dim)\n",
        "        self.key = nn.Linear(config.emb_dim, config.out_dim)\n",
        "        self.value = nn.Linear(config.emb_dim, config.out_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        q = self.query(input)\n",
        "        k = self.key(input)\n",
        "        v = self.value(input)\n",
        "\n",
        "        att_score = F.softmax(torch.bmm(q, k.transpose(1,2)) / math.sqrt(q.size(1)), -1)\n",
        "        self_att_rst = torch.bmm(att_score, v)\n",
        "        return self_att_rst"
      ],
      "metadata": {
        "id": "9a_L8dgby8uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.s_att = SelfAttention(config)\n",
        "\n",
        "    def forward(self, input):\n",
        "        rst_list = []\n",
        "        for _ in range(config.num_head):\n",
        "            rst_list.append(self.s_att(input))\n",
        "        output = torch.concat(rst_list, -1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "iQWBnraEy-VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FF(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(config.emb_dim, config.hid_dim)\n",
        "        self.act =  nn.ELU()\n",
        "        self.lin2 = nn.Linear(config.hid_dim, config.emb_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = self.lin1(input)\n",
        "        input = self.act(input)\n",
        "        input = self.lin2(input)\n",
        "        return input"
      ],
      "metadata": {
        "id": "11f_xTMy1t8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.norm2 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.attention = MultiHeadAttention(config)\n",
        "        self.ff = FF(config)\n",
        "\n",
        "    def forward(self, input):\n",
        "        concat_rst = self.attention(input)\n",
        "        nor_rst1 = self.norm1(concat_rst + input)\n",
        "        f_rst = self.ff(nor_rst1)\n",
        "        nor_rst2 = self.norm2(f_rst + nor_rst1)\n",
        "        return nor_rst2"
      ],
      "metadata": {
        "id": "zP-iF0gj1xmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.emb = Embedding(config)\n",
        "        self.trans = TransformerEncoder(config)\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = self.emb(input)\n",
        "        input = self.trans(input)\n",
        "        return input"
      ],
      "metadata": {
        "id": "RxDABDCL1zOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder 스크래치"
      ],
      "metadata": {
        "id": "QmwPK9nt1shh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config =Config()"
      ],
      "metadata": {
        "id": "iahvLA1s2yQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(config)"
      ],
      "metadata": {
        "id": "pmvmSckc2dtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_rst = encoder(input_tensor)"
      ],
      "metadata": {
        "id": "asoAvoXc2hT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "    dim_k = query.size(-1)\n",
        "    scores = torch.bmm(query, key.transpose(1, 2)) / math.sqrt(dim_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
        "    weights = F.softmax(scores, dim=-1)\n",
        "    return weights.bmm(value)"
      ],
      "metadata": {
        "id": "NFjB9L5tpNyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_layer = Embedding(config)"
      ],
      "metadata": {
        "id": "MNtaRTasuObk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = emb_layer(input_tensor)"
      ],
      "metadata": {
        "id": "4qeHRnUIuSf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim=emb.size(2)"
      ],
      "metadata": {
        "id": "eK80DNMsuVN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = nn.Linear(emb_dim, emb_dim)\n",
        "key = nn.Linear(emb_dim, emb_dim)\n",
        "value = nn.Linear(emb_dim, emb_dim)"
      ],
      "metadata": {
        "id": "DvGV8OPTuwOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = query(emb)\n",
        "k = key(emb)\n",
        "v = value(emb)"
      ],
      "metadata": {
        "id": "neSnmdLZvFRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q.size(-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_OmmQivdwkt",
        "outputId": "20d71916-a5c6-41c7-9868-6f1543b19385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "NLLc0uOLdFE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tri = np.tri(4, 4, 0)"
      ],
      "metadata": {
        "id": "U8qTQFXmdDRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tri = torch.tensor(tri)"
      ],
      "metadata": {
        "id": "x58AoBjJdTFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_rst= scaled_dot_product_attention(q,k,v, mask = tri)"
      ],
      "metadata": {
        "id": "XbRNd6ANvSjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_rst.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSnN2CB6vU4p",
        "outputId": "48540aa3-66b2-4f1c-b5c4-f28b8be99929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_rst"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6yPy3hofQwb",
        "outputId": "9f7acf07-fbcf-4efb-df67-d89bffbb539c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.2788, -0.6527,  0.9656, -0.7796, -0.1122,  1.4655, -0.5020,\n",
              "          -0.1309, -0.8396,  0.0361],\n",
              "         [ 0.0063,  0.4250,  0.7432,  0.2747,  0.1872, -0.3472, -0.7626,\n",
              "          -0.6438,  0.2820,  0.6354],\n",
              "         [-0.0512,  0.4165,  0.7532,  0.5267,  0.2384, -0.7517, -0.6756,\n",
              "          -0.6845,  0.2947,  0.7588],\n",
              "         [ 0.1865, -0.3995,  0.7454,  0.1813,  0.0841, -0.2564, -0.0536,\n",
              "          -0.2857, -0.5558,  0.4451]]], grad_fn=<BmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "att_score = F.softmax(torch.bmm(f_rst, enc_rst.transpose(1,2)) / math.sqrt(f_rst.size(1)), -1)\n",
        "s_rst = torch.bmm(att_score, enc_rst)"
      ],
      "metadata": {
        "id": "wJHlbaUMvrjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(s_rst.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuRfSaQ9xBb6",
        "outputId": "bda903d6-6f8f-49b1-fc21-1b767b106f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l_dim = s_rst.size(-1)"
      ],
      "metadata": {
        "id": "_vtX1coXxhWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hid_dim = 50"
      ],
      "metadata": {
        "id": "1j3VHTLdxC6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin1 = nn.Linear(l_dim, hid_dim)\n",
        "act =  nn.ELU()\n",
        "lin2 = nn.Linear(hid_dim, l_dim)"
      ],
      "metadata": {
        "id": "NshtpKR-xaZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_r = lin2(act(lin1(s_rst)))"
      ],
      "metadata": {
        "id": "V7pNvQ8Fxa2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal = nn.BatchNorm1d(4)"
      ],
      "metadata": {
        "id": "HFT9l_KnxqPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_r.shape"
      ],
      "metadata": {
        "id": "2vLpg4cpiUwK",
        "outputId": "c720d2a7-d475-4454-a60d-46d5e46fb615",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##모듈화"
      ],
      "metadata": {
        "id": "PToZIY991vlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "    dim_k = query.size(-1)\n",
        "    scores = torch.bmm(query, key.transpose(1, 2)) / math.sqrt(dim_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
        "    weights = F.softmax(scores, dim=-1)\n",
        "    return weights.bmm(value)"
      ],
      "metadata": {
        "id": "ili5ZUY611_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(config.emb_dim, config.out_dim)\n",
        "        self.key = nn.Linear(config.emb_dim, config.out_dim)\n",
        "        self.value = nn.Linear(config.emb_dim, config.out_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        q = self.query(input)\n",
        "        k = self.key(input)\n",
        "        v = self.value(input)\n",
        "\n",
        "        self_att_rst = scaled_dot_product_attention(q,k,v)\n",
        "        return self_att_rst"
      ],
      "metadata": {
        "id": "gIHCCkp7ys40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DMultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.s_att = DSelfAttention(config)\n",
        "\n",
        "    def forward(self, input):\n",
        "        rst_list = []\n",
        "        for _ in range(config.num_head):\n",
        "            rst_list.append(self.s_att(input))\n",
        "        output = torch.concat(rst_list, -1)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "IA4eKaE0ymV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.norm2 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.norm3 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.attention = DMultiHeadAttention(config)\n",
        "        self.ff = FF(config)\n",
        "\n",
        "    def forward(self, input, E_output):\n",
        "        concat_rst = self.attention(input)\n",
        "        nor_rst1 = self.norm1(concat_rst + input)\n",
        "\n",
        "        att_score = F.softmax(torch.bmm(nor_rst1, E_output.transpose(1,2)) / math.sqrt(nor_rst1.size(1)), -1)\n",
        "        s_rst = torch.bmm(att_score, E_output)\n",
        "\n",
        "        nor_rst2 = self.norm2(nor_rst1 + s_rst)\n",
        "\n",
        "        f_rst = self.ff(nor_rst2)\n",
        "\n",
        "        nor_rst3 = self.norm3(f_rst + nor_rst1)\n",
        "        return nor_rst3"
      ],
      "metadata": {
        "id": "sZ2TJHH_ya2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.emb = Embedding(config)\n",
        "        self.trans = TransformerDecoder(config)\n",
        "\n",
        "    def forward(self, D_input, E_output):\n",
        "        input = self.emb(D_input)\n",
        "        input = self.trans(input, E_output)\n",
        "        return input"
      ],
      "metadata": {
        "id": "90rHRV4gx-i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(config)"
      ],
      "metadata": {
        "id": "7Q4VyFply5np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder(input_tensor, enc_rst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoq-hHfTzDS5",
        "outputId": "b29a5137-9265-485d-b956-f08deff1a1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1298, -0.2773,  1.2603,  0.2071,  0.1946, -2.6092,  0.0442,\n",
              "           1.1747,  0.0782, -0.2024],\n",
              "         [ 1.4810,  1.1300, -0.2403, -1.3343, -1.7008,  0.7645,  0.3807,\n",
              "           0.4151,  0.0502, -0.9460],\n",
              "         [-0.4524,  0.4533,  0.9527, -0.2169,  0.6101, -2.1351,  1.5977,\n",
              "           0.4272, -0.2986, -0.9380],\n",
              "         [ 2.0670,  0.8960, -0.3170, -0.8146, -1.5359,  1.1211, -0.3260,\n",
              "          -0.2212, -0.3585, -0.5109]]], grad_fn=<NativeBatchNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qsKUXqHbx18i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}